{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_algorithm_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO5GHcBosupZ"
      },
      "source": [
        "# 分類アルゴリズムの紹介　1\r\n",
        "\r\n",
        "## 損失関数型アルゴリズム\r\n",
        "\r\n",
        "モデルの構造は数式の関数で決められていて\\\r\n",
        "パラメータを損失関数が0二近づくように\\\r\n",
        "調整・最適化していく特徴を持つモデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX0l4bfYHNwl"
      },
      "source": [
        "# 日本語化ライブラリ導入\n",
        "!pip install japanize-matplotlib | tail -n 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2awHTZPdsupd"
      },
      "source": [
        "# 共通事前処理\n",
        "\n",
        "# 余分なワーニングを非表示にする\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 必要ライブラリのimport\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# matplotlib日本語化対応\n",
        "import japanize_matplotlib\n",
        "\n",
        "# データフレーム表示用関数\n",
        "from IPython.display import display\n",
        "\n",
        "# 表示オプション調整\n",
        "# numpyの浮動小数点の表示精度\n",
        "np.set_printoptions(suppress=True, precision=4)\n",
        "# pandasでの浮動小数点の表示精度\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "# データフレームですべての項目を表示\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "# グラフのデフォルトフォント指定\n",
        "plt.rcParams[\"font.size\"] = 14\n",
        "# 乱数の種\n",
        "random_seed = 123"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYjQM4aPsuq4"
      },
      "source": [
        "## 0. サンプルコーディングで用いるデータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVwYIDVVsuq7"
      },
      "source": [
        "# サンプルデータの生成\n",
        "\n",
        "# ライブラリインポート\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# 線形分離型\n",
        "X1, y1 = make_classification(n_features=2, n_redundant=0, \n",
        "    n_informative=2, random_state=random_seed, \n",
        "    n_clusters_per_class=1, n_samples=200, n_classes=2)\n",
        "\n",
        "# 三日月型 (線形分離不可)\n",
        "X2, y2 = make_moons(noise = 0.05, random_state=random_seed, \n",
        "    n_samples=200)\n",
        "\n",
        "# 円形 (線形分離不可)\n",
        "X3, y3 = make_circles(noise = 0.02, random_state=random_seed, \n",
        "    n_samples=200)\n",
        "\n",
        "# 3種類のデータをDataListに保存\n",
        "DataList = [(X1, y1), (X2, y2), (X3, y3)]\n",
        "\n",
        "# N: データの種類数\n",
        "N = len(DataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCZVCPJqsurE",
        "scrolled": true
      },
      "source": [
        "# 散布図表示\n",
        "plt.figure(figsize=(15,4))\n",
        "\n",
        "# カラーマップ定義\n",
        "from matplotlib.colors import ListedColormap\n",
        "cmap = ListedColormap(['#0000FF', '#000000'])\n",
        "\n",
        "for i, data in enumerate(DataList):\n",
        "    X, y = data\n",
        "    ax = plt.subplot(1, N, i+1)\n",
        "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tg0HurlsurQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 決定境界の表示関数\n",
        "def plot_boundary(ax, x, y, algorithm):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
        "            test_size=0.5, random_state=random_seed)\n",
        "    # カラーマップ定義\n",
        "    from matplotlib.colors import ListedColormap\n",
        "    cmap1 = plt.cm.bwr\n",
        "    cmap2 = ListedColormap(['#0000FF', '#000000'])\n",
        "\n",
        "    h = 0.005\n",
        "    # アルゴリズムでの学習\n",
        "    algorithm.fit(x_train, y_train)\n",
        "    # 学習結果の取得\n",
        "    score_test = algorithm.score(x_test, y_test)\n",
        "    score_train = algorithm.score(x_train, y_train)\n",
        "\n",
        "    # モデルの確信度を表示するための処理\n",
        "    f1_min = x[:, 0].min() - 0.5\n",
        "    f1_max = x[:, 0].max() + 0.5\n",
        "    f2_min = x[:, 1].min() - 0.5\n",
        "    f2_max = x[:, 1].max() + 0.5\n",
        "    f1, f2 = np.meshgrid(np.arange(f1_min, f1_max, h), \n",
        "                         np.arange(f2_min, f2_max, h))\n",
        "    # アルゴリズムによって処理を分ける\n",
        "    # 分類の確信度はdecision_functionとpredict_proba選べるがpredict_probaしかないアルゴリズムがある\n",
        "    if hasattr(algorithm, \"decision_function\"):\n",
        "        # decision_functionはレンジなしの信頼度を表す。\n",
        "        Z = algorithm.decision_function(np.c_[f1.ravel(), f2.ravel()])\n",
        "        Z = Z.reshape(f1.shape)\n",
        "        ax.contour(f1, f2, Z, levels=[0], linewidth=2)\n",
        "    else:\n",
        "        # predict_probaはそのクラスに分類される確率を表す。\n",
        "        Z = algorithm.predict_proba(np.c_[f1.ravel(), f2.ravel()])[:, 1]\n",
        "        Z = Z.reshape(f1.shape)\n",
        "\n",
        "    # エリアを表示する\n",
        "    ax.contourf(f1, f2, Z, cmap=cmap1, alpha=0.3)\n",
        "    \n",
        "    # 散布図の表示\n",
        "    ax.scatter(x_test[:,0], x_test[:,1], c=y_test, cmap=cmap2)\n",
        "    ax.scatter(x_train[:,0], x_train[:,1], c=y_train, cmap=cmap2, marker='x')\n",
        "    # 学習結果の表示\n",
        "    text = f'検証:{score_test:.2f}  訓練: {score_train:.2f}'\n",
        "    ax.text(f1.max() - 0.3, f2.min() + 0.3, text, horizontalalignment='right',\n",
        "    fontsize=18) \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GnEs-HIsurX"
      },
      "source": [
        "# 散布図と決定境界の表示関数\n",
        "\n",
        "def plot_boundaries(algorithm, DataList):\n",
        "    plt.figure(figsize=(15,4))\n",
        "    for i, data in enumerate(DataList):\n",
        "        X, y = data\n",
        "        ax = plt.subplot(1, N, i+1)\n",
        "        plot_boundary(ax, X, y, algorithm)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QK7la8bsurc"
      },
      "source": [
        "# 1. ロジスティック回帰\r\n",
        "\r\n",
        "## ロジスティック回帰は、直線で分類しようとする\r\n",
        "\r\n",
        "### 概要\r\n",
        "入力情報を1次関数にかけて結果を出力する\\\r\n",
        "その結果をシグモイド関数にかけて、0から1の値に変換する\\\r\n",
        "変換したい値が0.5より大きい場合は１\\\r\n",
        "変換したい値が0.5より小さい場合は0\\\r\n",
        "として予測結果とする\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hjdypwfGxjT"
      },
      "source": [
        "#### シグモイド関数のグラフ表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "665hrivYsurd"
      },
      "source": [
        "# シグモイド関数の定義\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "# xのデータ準備\n",
        "x = np.linspace(-5, 5, 101)\n",
        "\n",
        "# yのデータ準備\n",
        "y = sigmoid(x)\n",
        "\n",
        "# グラフ表示\n",
        "plt.plot(x, y, label='シグモイド関数', c='b', lw=2)\n",
        "\n",
        "# 凡例表示\n",
        "plt.legend()\n",
        "\n",
        "# 方眼表示\n",
        "plt.grid()\n",
        "\n",
        "# グラフ描画\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H__cQb6suri"
      },
      "source": [
        "# ロジスティック回帰の散布図・分類結果表示\n",
        "\n",
        "# アルゴリズムの選定\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "algorithm = LogisticRegression(random_state=random_seed)\n",
        "\n",
        "# アルゴリズムの持つパラメータの表示 \n",
        "print(algorithm)\n",
        "\n",
        "# 表示関数の呼び出し\n",
        "plot_boundaries(algorithm, DataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-u8BluSoMHp"
      },
      "source": [
        "## ロジスティック回帰は、直線で分類しようとする\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lGjUfRvsur1"
      },
      "source": [
        "# 2.サポートベクターマシン(カーネル)\r\n",
        "\r\n",
        "## 2次元のデータを3次元に拡張して分類しようとする\r\n",
        "\r\n",
        "### 概要\r\n",
        "\r\n",
        "カーネル法という次元拡張する方法は、\\\r\n",
        "ガウスカーネル、多項式カーネル、シグモイドカーネルなどがある\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "ガウスカーネルで、サンプルデータに境界線を引いてみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDMaaX92vo4N"
      },
      "source": [
        "from mpl_toolkits.mplot3d.axes3d import Axes3D\r\n",
        "\r\n",
        "# 2次元乱数を生成\r\n",
        "x = np.random.rand(100)\r\n",
        "y = np.random.rand(100)\r\n",
        " \r\n",
        "# 散布図を描画\r\n",
        "# 2次元散布図\r\n",
        "plt.scatter(X1[:,0], X1[:,1], c=y1, cmap=cmap)\r\n",
        "\r\n",
        "# 3次元乱数を生成\r\n",
        "z = np.random.rand(len(X1[:,0]))\r\n",
        "\r\n",
        "# figureを生成する\r\n",
        "fig = plt.figure()\r\n",
        "# axをfigureに設定する\r\n",
        "ax = Axes3D(fig)\r\n",
        "\r\n",
        "# 散布図を描画\r\n",
        "# 3次元散布図\r\n",
        "ax.scatter(X1[:,0], z, X1[:,1],  c=y1, cmap=cmap)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSpjxSbMsur2",
        "scrolled": true
      },
      "source": [
        "# SVM (カーネル)の散布図・分類結果表示\n",
        "\n",
        "# アルゴリズムの選定\n",
        "from sklearn.svm import SVC\n",
        "algorithm = SVC(kernel='rbf', random_state=random_seed)\n",
        "\n",
        "# アルゴリズムの持つパラメータの表示 \n",
        "print(algorithm)\n",
        "\n",
        "# 表示関数の呼び出し\n",
        "plot_boundaries(algorithm, DataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtH_8tdKsusf"
      },
      "source": [
        "# 3 ニューラルネットワーク\r\n",
        "\r\n",
        "##　\r\n",
        "\r\n",
        "### 概要\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "MPLClassifier\\\r\n",
        "入力層と隠れ層と出力層が全結合である、もっとも単純なディープラーニング\\\r\n",
        "分類の機械学習をするときに利用される"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ4Kx1UBSATK"
      },
      "source": [
        "# ニューラルネットワークの散布図・分類結果表示\n",
        "# ノードが1層の場合は、ロジスティック回帰のような境界線の表示をする\n",
        "\n",
        "# アルゴリズムの選定\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "algorithm = MLPClassifier(random_state=random_seed)\n",
        "\n",
        "# アルゴリズムの持つパラメータの表示 \n",
        "print(algorithm)\n",
        "\n",
        "# 表示関数の呼び出し\n",
        "plot_boundaries(algorithm, DataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Nrq4XQsusg",
        "scrolled": false
      },
      "source": [
        "# ニューラルネットワークの散布図・分類結果表示\n",
        "# ノードが100層の場合は、カーネル法のような境界線を表示する\n",
        "\n",
        "# アルゴリズムの選定\n",
        "# 隠れ層ノード数=(100,100)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "algorithm = MLPClassifier(hidden_layer_sizes=(100,100), random_state=random_seed)\n",
        "\n",
        "# アルゴリズムの持つパラメータの表示 \n",
        "print(algorithm)\n",
        "\n",
        "# 表示関数の呼び出し\n",
        "plot_boundaries(algorithm, DataList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cor27JFxsusf"
      },
      "source": [
        "### 参考\n",
        "バージョン確認用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxxTH6Dqsus4"
      },
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}