{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mO5GHcBosupZ"
   },
   "source": [
    "# 分類アルゴリズム選択　2\n",
    "\n",
    "## 決定木型アルゴリズム\n",
    "\n",
    "モデルの構造は、ノードである項目と閾値から2つに分岐し、\\\n",
    "繰り返して分類していく特徴を持つモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JATHKQVl0dQE"
   },
   "source": [
    "## 実行のための前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FX0l4bfYHNwl",
    "outputId": "818d6679-b7a3-489c-f4a1-4b0d6c75f0d8"
   },
   "outputs": [],
   "source": [
    "# 日本語化ライブラリ導入\n",
    "!pip install japanize-matplotlib | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seabornとは、Pythonのデータ可視化ライブラリで、同じPythonの可視化ライブラリであるmatplotlibが内部で動いています\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2awHTZPdsupd"
   },
   "outputs": [],
   "source": [
    "# 共通事前処理\n",
    "\n",
    "# 余分なワーニングを非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 必要ライブラリのimport\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# matplotlib日本語化対応\n",
    "import japanize_matplotlib\n",
    "\n",
    "# データフレーム表示用関数\n",
    "from IPython.display import display\n",
    "\n",
    "# 表示オプション調整\n",
    "# numpyの浮動小数点の表示精度\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "# pandasでの浮動小数点の表示精度\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "# データフレームですべての項目を表示\n",
    "pd.set_option(\"display.max_columns\",None)\n",
    "# グラフのデフォルトフォント指定\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "# 乱数の種\n",
    "random_seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYjQM4aPsuq4"
   },
   "source": [
    "# 0. サンプルコーディングで用いるデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVwYIDVVsuq7"
   },
   "outputs": [],
   "source": [
    "# サンプルデータの生成\n",
    "\n",
    "# ライブラリインポート\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 線形分離型\n",
    "X1, y1 = make_classification(n_features=2, n_redundant=0, \n",
    "    n_informative=2, random_state=random_seed, \n",
    "    n_clusters_per_class=1, n_samples=200, n_classes=2)\n",
    "\n",
    "# 三日月型 (線形分離不可)\n",
    "X2, y2 = make_moons(noise = 0.05, random_state=random_seed, \n",
    "    n_samples=200)\n",
    "\n",
    "# 円形 (線形分離不可)\n",
    "X3, y3 = make_circles(noise = 0.02, random_state=random_seed, \n",
    "    n_samples=200)\n",
    "\n",
    "# 3種類のデータをDataListに保存\n",
    "DataList = [(X1, y1), (X2, y2), (X3, y3)]\n",
    "\n",
    "# N: データの種類数\n",
    "N = len(DataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "ZCZVCPJqsurE",
    "outputId": "e7c6795b-f033-4c42-bad2-b1c100b3620b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 散布図表示\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "# カラーマップ定義\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['#0000FF', '#000000'])\n",
    "\n",
    "for i, data in enumerate(DataList):\n",
    "    X, y = data\n",
    "    ax = plt.subplot(1, N, i+1)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKv9USYJ0tj-"
   },
   "source": [
    "## 学習結果を表示する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tg0HurlsurQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 決定境界の表示関数\n",
    "def plot_boundary(ax, x, y, algorithm):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,\n",
    "            test_size=0.5, random_state=random_seed)\n",
    "    # カラーマップ定義\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    cmap1 = plt.cm.bwr\n",
    "    cmap2 = ListedColormap(['#0000FF', '#000000'])\n",
    "\n",
    "    h = 0.005\n",
    "    # アルゴリズムでの学習\n",
    "    algorithm.fit(x_train, y_train)\n",
    "    # 学習結果の取得\n",
    "    score_test = algorithm.score(x_test, y_test)\n",
    "    score_train = algorithm.score(x_train, y_train)\n",
    "\n",
    "    # モデルの確信度を表示するための処理\n",
    "    f1_min = x[:, 0].min() - 0.5\n",
    "    f1_max = x[:, 0].max() + 0.5\n",
    "    f2_min = x[:, 1].min() - 0.5\n",
    "    f2_max = x[:, 1].max() + 0.5\n",
    "    f1, f2 = np.meshgrid(np.arange(f1_min, f1_max, h), \n",
    "                         np.arange(f2_min, f2_max, h))\n",
    "    # アルゴリズムによって処理を分ける\n",
    "    # 分類の確信度はdecision_functionとpredict_proba選べるがpredict_probaしかないアルゴリズムがある\n",
    "    if hasattr(algorithm, \"decision_function\"):\n",
    "        # decision_functionはレンジなしの信頼度を表す。\n",
    "        Z = algorithm.decision_function(np.c_[f1.ravel(), f2.ravel()])\n",
    "        Z = Z.reshape(f1.shape)\n",
    "        ax.contour(f1, f2, Z, levels=[0], linewidth=2)\n",
    "    else:\n",
    "        # predict_probaはそのクラスに分類される確率を表す。\n",
    "        Z = algorithm.predict_proba(np.c_[f1.ravel(), f2.ravel()])[:, 1]\n",
    "        Z = Z.reshape(f1.shape)\n",
    "\n",
    "    # エリアを表示する\n",
    "    ax.contourf(f1, f2, Z, cmap=cmap1, alpha=0.3)\n",
    "    \n",
    "    # 散布図の表示\n",
    "    ax.scatter(x_test[:,0], x_test[:,1], c=y_test, cmap=cmap2)\n",
    "    ax.scatter(x_train[:,0], x_train[:,1], c=y_train, cmap=cmap2, marker='x')\n",
    "    # 学習結果の表示\n",
    "    text = f'検証:{score_test:.2f}  訓練: {score_train:.2f}'\n",
    "    ax.text(f1.max() - 0.3, f2.min() + 0.3, text, horizontalalignment='right',\n",
    "    fontsize=18) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GnEs-HIsurX"
   },
   "outputs": [],
   "source": [
    "# 散布図と決定境界の表示関数\n",
    "\n",
    "def plot_boundaries(algorithm, DataList):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    for i, data in enumerate(DataList):\n",
    "        X, y = data\n",
    "        ax = plt.subplot(1, N, i+1)\n",
    "        plot_boundary(ax, X, y, algorithm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CijPD0UZsur6"
   },
   "source": [
    "# 1. 決定木\n",
    "\n",
    "##  ツリー構造、2分木を使って分類を行うモデル\n",
    "\n",
    "### 概要\n",
    "決定木の層の深さを決めることで、精度が上がったり下がったりする\\\n",
    "過学習についても見ていきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kpfi-I_ER3ZF"
   },
   "source": [
    " ##  決定木のイメージを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdxLMsRNsur8"
   },
   "outputs": [],
   "source": [
    "# 追加ライブラリのimport\n",
    "import seaborn as sns\n",
    "\n",
    "# サンプルデータの読み込み\n",
    "df_iris = sns.load_dataset(\"iris\")\n",
    "# 2種類の花に絞り込み\n",
    "df2 = df_iris[50:150]\n",
    "\n",
    "# データ分離\n",
    "X = df2.drop('species', axis=1)\n",
    "y = df2['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "mz9ydocPsur_",
    "outputId": "f097fe3e-6525-42d6-f897-66bc547b0761"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm = DecisionTreeClassifier(random_state=random_seed)\n",
    "algorithm.fit(X, y)\n",
    "\n",
    "# 決定木のツリー表示\n",
    "from sklearn import tree\n",
    "with open('iris-dtree.dot', mode='w') as f:\n",
    "    tree.export_graphviz( algorithm, out_file=f,\n",
    "        feature_names=X.columns, filled=True, rounded=True,  \n",
    "        special_characters=True, impurity=False, proportion=False\n",
    "    ) \n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "graph = pydotplus.graphviz.graph_from_dot_file('iris-dtree.dot')\n",
    "graph.write_png('iris-dtree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_XCm2eESFUD"
   },
   "source": [
    "## サンプルデータで分類した結果を示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "4Unapg7GsusF",
    "outputId": "fcaaaa5b-bb54-4d84-a252-d2ec88f17561"
   },
   "outputs": [],
   "source": [
    "# 決定木の散布図・分類結果表示\n",
    "\n",
    "# アルゴリズムの選定\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# アルゴリズムの持つパラメータの表示 \n",
    "print(algorithm)\n",
    "\n",
    "# 表示関数の呼び出し\n",
    "plot_boundaries(algorithm, DataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XCySUaHSTfw"
   },
   "source": [
    "ハイパーパラメータを変更して、過学習の状態を同じデータで再現\n",
    "\n",
    "max_depthというパラメータを変更\\\n",
    "決定木のツリーの層の深さを指定　デフォルトはNone(上限なし)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "lFwywes9susJ",
    "outputId": "3d6f3f56-c4d6-410a-9c58-4beee78090b2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 決定木の散布図・分類結果表示(max_depth=3の場合)\n",
    "\n",
    "# アルゴリズムの選定\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm = DecisionTreeClassifier(max_depth=3, \n",
    "    random_state=random_seed)\n",
    "\n",
    "# アルゴリズムの持つパラメータの表示 \n",
    "print(algorithm)\n",
    "\n",
    "# 表示関数の呼び出し\n",
    "plot_boundaries(algorithm, DataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EalfyOpBsusN"
   },
   "source": [
    "# 2. ランダムフォレスト\n",
    "\n",
    "## 簡易分類器による多数決で分類する\n",
    "\n",
    "### 概要\n",
    "データを複数に分割して分類器を作り、\\\n",
    "分類器の結果を集計して多数決により分類を決定する\n",
    "\n",
    "分類器で扱うデータは重複を許す方法をブートストラップ法という\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehcAEMhg1sL4"
   },
   "source": [
    "## ランダムフォレストの処理のイメージを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy6VBnLb5XaB"
   },
   "source": [
    "スライドへ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5Y2O48_1co2"
   },
   "source": [
    "## サンプルデータで分類した結果を示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LDlgCivsusS"
   },
   "outputs": [],
   "source": [
    "# ランダムフォレストの散布図・分類結果表示\n",
    "\n",
    "# アルゴリズムの選定\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm = RandomForestClassifier(random_state=random_seed)\n",
    "\n",
    "# アルゴリズムの持つパラメータの表示 \n",
    "print(algorithm)\n",
    "\n",
    "# 表示関数の呼び出し\n",
    "plot_boundaries(algorithm, DataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP8HIeqZsusW"
   },
   "source": [
    "# 3. XGBoost\n",
    "\n",
    "## 「アンサンブル」という複数の決定木を使って分類手法の中で、「バギング」と「ブースティング」を組み合わせたモデル\n",
    "\n",
    "### 概要\n",
    "\n",
    "アンサンブル：推定値と実測値の差を表しますバイアスと推定値のばらつきを\\\n",
    "表すバリアンスを上手く調整する手法群です。\n",
    "\n",
    "バギング：弱分類器を複数並べてその結果の多数決で分類する\n",
    "\n",
    "ブースティング：分類器の分類結果と正解データから新しい分類器を作成する工程を繰り返し、最終的な分類ヲする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Obvb4F3p1ibz"
   },
   "source": [
    "## ブースティングの処理のイメージを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZcTrbU3hbjd"
   },
   "source": [
    "スライドへ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG-HSHq51guk"
   },
   "source": [
    "## サンプルデータで分類した結果を示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rc__Yw46susX"
   },
   "outputs": [],
   "source": [
    "# XGBoostの散布図・分類結果表示\n",
    "\n",
    "# アルゴリズムの選定\n",
    "import xgboost\n",
    "algorithm = xgboost.XGBClassifier(random_state=random_seed)\n",
    "\n",
    "# アルゴリズムの持つパラメータの表示 \n",
    "print(algorithm)\n",
    "\n",
    "# 表示関数の呼び出し\n",
    "plot_boundaries(algorithm, DataList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cor27JFxsusf"
   },
   "source": [
    "## 参考\n",
    "バージョン確認用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxxTH6Dqsus4"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JATHKQVl0dQE",
    "yYjQM4aPsuq4",
    "oKv9USYJ0tj-",
    "CijPD0UZsur6",
    "Kpfi-I_ER3ZF",
    "w_XCm2eESFUD",
    "oG-HSHq51guk",
    "Cor27JFxsusf"
   ],
   "name": "02_algorithm_tree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
